# src/data_processors/optc_label_extractor.py

import torch
import pandas as pd
import logging
from typing import Dict, Any, List
from .label_extractor import LabelExtractor # Inherit from the base LabelExtractor

class OpTCLabelExtractor(LabelExtractor): # Inherit from base for common config/logger
    """
    Specialized label extractor for OpTC system-level provenance data (eCAR format).
    Maps processed labels (MITRE T-codes or BENIGN) to numerical IDs for neural network targets.
    """
    
    def __init__(self, config: Any):
        super().__init__(config) # Initializes logger and config
        
        # Define the primary attack types and MITRE techniques based on OpTC data
        # These mappings will be used to convert string labels to numerical IDs.
        # The 'label' column from OpTCProcessor will typically contain 'BENIGN' or a T-code.
        
        # Attack types (simplified, can be expanded to broader categories like DoS, Recon, etc.)
        # For OpTC, we primarily have specific T-codes or 'BENIGN'.
        # We'll map T-codes to a generic 'ATTACK' type for attack_type classification if needed,
        # otherwise, it's a binary (BENIGN/ATTACK) and then specific MITRE technique.
        self.attack_types = {'BENIGN': 0, 'ATTACK': 1} # Simplified binary classification for 'attack_type' head
        
        # MITRE techniques will be dynamically built or loaded.
        # For Phase 1, we map directly from the T-codes generated by OpTCProcessor.
        # Ensure that config.num_mitre_techniques is sufficiently large to cover all T-codes.
        # The actual T-codes should come from OpTCProcessor's `action_attack_mapping`
        # Or, we dynamically build the vocab for MITRE techniques during data loading.
        
        self.mitre_techniques_vocab = {'BENIGN': 0} # Start with BENIGN
        self._next_mitre_id = 1 # Start from 1 for T-codes
        
        # This mapping will be populated dynamically if T-codes are seen
        # A more robust solution might load this from a pre-defined MITRE ontology
        # or from the `action_attack_mapping` in OpTCProcessor.

    def get_mitre_technique_id(self, technique_code: str) -> int:
        """Map MITRE technique code (e.g., 'T1005') to a numerical ID."""
        if technique_code not in self.mitre_techniques_vocab:
            self.mitre_techniques_vocab[technique_code] = self._next_mitre_id
            self._next_mitre_id += 1
        return self.mitre_techniques_vocab[technique_code]

    def extract_labels(self, events_df: pd.DataFrame) -> Dict[str, torch.Tensor]:
        """
        Extracts labels for attack presence, attack type, MITRE technique, severity, and confidence.
        Assumes 'label' and 'attack_presence' columns are already present from OpTCProcessor.
        """
        if 'label' not in events_df.columns or 'attack_presence' not in events_df.columns:
            self.logger.error("Missing required 'label' or 'attack_presence' column from OpTCProcessor output.")
            raise ValueError("Required label columns missing for OpTCLabelExtractor.")

        # --- FIX: Avoid SettingWithCopyWarning by using .loc for assignment ---
        events_df.loc[:, 'label'] = events_df['label'].astype(str)

        # 1. Attack Presence (Binary: 0=BENIGN, 1=ATTACK)
        # Directly use 'attack_presence' column from OpTCProcessor
        attack_presence_labels = events_df['attack_presence'].values
        
        # 2. Attack Type (Simplified: BENIGN/ATTACK or broader categories)
        # For OpTC, if the label is 'BENIGN', it's 0, otherwise it's 1 for 'ATTACK'.
        attack_type_labels = events_df['label'].apply(
            lambda x: self.attack_types['BENIGN'] if x == 'BENIGN' else self.attack_types['ATTACK']
        ).values
        
        # 3. MITRE Technique (Specific T-code IDs)
        mitre_technique_labels = []
        for label in events_df['label'].values:
            mitre_technique_labels.append(self.get_mitre_technique_id(label)) # Map each T-code (or BENIGN) to an ID

        # Convert to numpy arrays first, then to torch tensors
        # Ensure integer types for classification targets
        extracted_labels = {
            'attack_presence': torch.tensor(attack_presence_labels, dtype=torch.long),
            'attack_type': torch.tensor(attack_type_labels, dtype=torch.long),
            'mitre_technique': torch.tensor(mitre_technique_labels, dtype=torch.long),
            # Severity and Confidence are often regression tasks,
            # For OpTC, these might be inferred or fixed initially if not directly in raw data.
            # OpTC events don't have inherent 'severity' or 'confidence' in standard fields.
            # These are usually outputs of your model's classification or a fixed value for ground truth.
            # For ground truth, you can assign them based on 'attack_presence'.
            'severity': torch.tensor(
                [0.7 if p == 1 else 0.0 for p in attack_presence_labels], dtype=torch.float32
            ).unsqueeze(1), # Unsqueeze for (N, 1) shape
            'confidence': torch.tensor(
                [1.0 for _ in attack_presence_labels], dtype=torch.float32
            ).unsqueeze(1) # Unsqueeze for (N, 1) shape
        }
        
        self.logger.info(f"Extracted labels for {len(events_df)} events.")
        self.logger.info(f"MITRE techniques vocabulary size: {len(self.mitre_techniques_vocab)} (mapping: {dict(list(self.mitre_techniques_vocab.items())[:5])}...)") # Log first few mappings
        
        # Update config.num_mitre_techniques dynamically
        self.config.num_mitre_techniques = len(self.mitre_techniques_vocab)
        self.config.num_attack_types = len(self.attack_types) # Ensure this matches the 2 (BENIGN/ATTACK)
        
        return extracted_labels